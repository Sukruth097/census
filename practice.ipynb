{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymongo\n",
    "import certifi\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "now=datetime.now().strftime('%Y-%m-%d')\n",
    "print(now)\n",
    "\n",
    "ca = certifi.where()\n",
    "file_dir =\"client-data\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client-data1\\data\\2023_04_01_2023_04_19_finance_complaint.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41627, 18)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=os.listdir(file_dir)\n",
    "file_path = os.path.join(file_dir, file[0])\n",
    "print(file_path)\n",
    "# specify the directory path where the JSON file is stored\n",
    "# directory = file_dir\n",
    "# # get the filename of the JSON file from the directory\n",
    "# json_filename = [f for f in os.listdir(directory) if f.endswith('.json')][0]\n",
    "# print(json_filename)\n",
    "# # join the directory path with the JSON filename\n",
    "# json_file_path = os.path.join(directory, json_filename)\n",
    "# # read the JSON file into a pandas dataframe\n",
    "df = pd.read_json(file_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client-data1\\data\\2023_04_01_2023_04_19_finance_complaint.json\n",
      "(41627, 18)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if len(os.listdir(file_dir))>1:\n",
    "    new_df = []\n",
    "    for file in os.listdir(file_dir):\n",
    "        file = os.path.join(file_dir,file)\n",
    "        print(file)\n",
    "        df = pd.read_json(file)\n",
    "        print(df.shape)\n",
    "        # append the dataframe to the list\n",
    "        new_df.append(df)\n",
    "    # concatenate all dataframes into a single dataframe\n",
    "    result_df = pd.concat(new_df)\n",
    "    print(result_df.shape)\n",
    "else:\n",
    "    # read the single JSON file into a pandas dataframe\n",
    "    file=os.listdir(file_dir)\n",
    "    file_path = os.path.join(file_dir, file[0])\n",
    "    print(file_path)\n",
    "    # read the JSON file into a pandas dataframe\n",
    "    df = pd.read_json(file_path)\n",
    "    print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41627, 18)\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_URL=\"mongodb+srv://sukruth:Asdfghjkl97@cluster0.yd8mlom.mongodb.net/?retryWrites=true&w=majority\"\n",
    "DATABASE_NAME =\"census\"\n",
    "COLLECTION_NAME=\"finance_complaint_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(MONGODB_URL,tlsCAFile = ca)\n",
    "collection = client[DATABASE_NAME][COLLECTION_NAME]\n",
    "# print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pymongo.cursor.Cursor'>\n"
     ]
    }
   ],
   "source": [
    "data =collection.find({},{\"_id\": 0})\n",
    "print(type(data))\n",
    "json_data = []\n",
    "for document in data:\n",
    "    json_data.append(document)\n",
    "# json_data\n",
    "# json.loads(json_util.dumps(data))\n",
    "with open('dataingestion.json', 'w') as f:\n",
    "    json.dump(json_data, f,default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =list(collection.find({},{\"_id\": 0}))\n",
    "\n",
    "with open('dataingestion.json', 'w') as f:\n",
    "    json.dump(data, f,default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49881, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('dataingestion.json')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023_04_01_2023_04_19_finance_complaint.json'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41627, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41627"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=os.listdir(file_dir)\n",
    "file_path = os.path.join(file_dir, file[0])\n",
    "df = pd.read_json(file_path)\n",
    "print(df.shape)\n",
    "df.complaint_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['complaint_id'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41641"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new= df[['complaint_id']]\n",
    "print(df_new.columns)\n",
    "\n",
    "projection = {'complaint_id': 1, '_id': 0}\n",
    "\n",
    "# query the collection and retrieve only the complaint_id field\n",
    "result = collection.find({}, projection)\n",
    "\n",
    "# convert the result to a pandas DataFrame\n",
    "df_old = pd.DataFrame(list(result))\n",
    "df_old = df_old.rename(columns={'complaint_id':'old_complaint_id'})\n",
    "df_old['old_complaint_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['complaint_id', 'old_complaint_id'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(df_new, df_old, left_on='complaint_id', right_on='old_complaint_id',how='left')\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>old_complaint_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>6820728</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>6785971</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>6793988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14057</th>\n",
       "      <td>6794731</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       complaint_id  old_complaint_id\n",
       "8574        6820728               NaN\n",
       "9127        6785971               NaN\n",
       "14017       6793988               NaN\n",
       "14057       6794731               NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_records=merged_df[merged_df['complaint_id'].notna() & merged_df['old_complaint_id'].isna()]\n",
    "new_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>date_sent_to_company</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>tags</th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>timely</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <th>company_response</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>company</th>\n",
       "      <th>date_received</th>\n",
       "      <th>state</th>\n",
       "      <th>consumer_disputed</th>\n",
       "      <th>company_public_response</th>\n",
       "      <th>sub_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td></td>\n",
       "      <td>2023-04-10T12:00:00-05:00</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>93706.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6820728</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Web</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>2023-04-10T12:00:00-05:00</td>\n",
       "      <td>CA</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>Reporting company used your report improperly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td></td>\n",
       "      <td>2023-04-04T12:00:00-05:00</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>46896.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6785971</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Other</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Web</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>2023-04-04T12:00:00-05:00</td>\n",
       "      <td>IN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>Credit inquiries on your report that you don't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td></td>\n",
       "      <td>2023-04-04T12:00:00-05:00</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>33016.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6793988</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Web</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>2023-04-04T12:00:00-05:00</td>\n",
       "      <td>FL</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>Reporting company used your report improperly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14057</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td></td>\n",
       "      <td>2023-04-04T12:00:00-05:00</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>80013.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6794731</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Web</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>2023-04-04T12:00:00-05:00</td>\n",
       "      <td>CO</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>Reporting company used your report improperly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 product   \n",
       "8574   Credit reporting, credit repair services, or o...  \\\n",
       "9127   Credit reporting, credit repair services, or o...   \n",
       "14017  Credit reporting, credit repair services, or o...   \n",
       "14057  Credit reporting, credit repair services, or o...   \n",
       "\n",
       "      complaint_what_happened       date_sent_to_company   \n",
       "8574                           2023-04-10T12:00:00-05:00  \\\n",
       "9127                           2023-04-04T12:00:00-05:00   \n",
       "14017                          2023-04-04T12:00:00-05:00   \n",
       "14057                          2023-04-04T12:00:00-05:00   \n",
       "\n",
       "                             issue       sub_product  zip_code  tags   \n",
       "8574   Improper use of your report  Credit reporting   93706.0  None  \\\n",
       "9127   Improper use of your report  Credit reporting   46896.0  None   \n",
       "14017  Improper use of your report  Credit reporting   33016.0  None   \n",
       "14057  Improper use of your report  Credit reporting   80013.0  None   \n",
       "\n",
       "       complaint_id timely consumer_consent_provided company_response   \n",
       "8574        6820728    Yes                      None      In progress  \\\n",
       "9127        6785971    Yes                     Other      In progress   \n",
       "14017       6793988    Yes                      None      In progress   \n",
       "14057       6794731    Yes                      None      In progress   \n",
       "\n",
       "      submitted_via                                 company   \n",
       "8574            Web  TRANSUNION INTERMEDIATE HOLDINGS, INC.  \\\n",
       "9127            Web  TRANSUNION INTERMEDIATE HOLDINGS, INC.   \n",
       "14017           Web                           EQUIFAX, INC.   \n",
       "14057           Web                           EQUIFAX, INC.   \n",
       "\n",
       "                   date_received state consumer_disputed   \n",
       "8574   2023-04-10T12:00:00-05:00    CA               N/A  \\\n",
       "9127   2023-04-04T12:00:00-05:00    IN               N/A   \n",
       "14017  2023-04-04T12:00:00-05:00    FL               N/A   \n",
       "14057  2023-04-04T12:00:00-05:00    CO               N/A   \n",
       "\n",
       "      company_public_response   \n",
       "8574                     None  \\\n",
       "9127                     None   \n",
       "14017                    None   \n",
       "14057                    None   \n",
       "\n",
       "                                               sub_issue  \n",
       "8574       Reporting company used your report improperly  \n",
       "9127   Credit inquiries on your report that you don't...  \n",
       "14017      Reporting company used your report improperly  \n",
       "14057      Reporting company used your report improperly  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_records=df[df['complaint_id'].isin(new_records['complaint_id'])]\n",
    "all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1e1ab31feb0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert the new records into the collection\n",
    "records = all_records.to_dict('records')\n",
    "collection.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:29\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = pd.read_json(file_path)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "# Create a directory for the new folder\n",
    "new_folder = 'archive'\n",
    "if not os.path.exists(new_folder):\n",
    "    os.makedirs(new_folder,exist_ok=True)\n",
    "# file=os.listdir(file_dir)\n",
    "# file_path = os.path.join(file_dir, file[0])\n",
    "# df = pd.read_json(file_path)\n",
    "\n",
    "\n",
    "if len(os.listdir(file_dir))>1:\n",
    "    new_df = []\n",
    "    for file in os.listdir(file_dir):\n",
    "        file = os.path.join(file_dir,file)\n",
    "        # print(file)\n",
    "        df = pd.read_json(file)\n",
    "        # print(df.shape)\n",
    "        # append the dataframe to the list\n",
    "        new_df.append(df)\n",
    "    # concatenate all dataframes into a single dataframe\n",
    "    df = pd.concat(new_df)\n",
    "    print(df.shape)\n",
    "else:\n",
    "    # read the single JSON file into a pandas dataframe\n",
    "    file=os.listdir(file_dir)\n",
    "    file_path = os.path.join(file_dir, file[0])\n",
    "    print(file_path)\n",
    "    # read the JSON file into a pandas dataframe\n",
    "    df = pd.read_json(file_path)\n",
    "    print(df.shape)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "documents = df.to_dict('records')\n",
    "\n",
    "# Check if the collection is empty\n",
    "if collection.count_documents({}) == 0:\n",
    "    # If the collection is empty, insert the documents into the collection using insert_many()\n",
    "    result = collection.insert_many(documents)\n",
    "\n",
    "    # Print the number of documents inserted\n",
    "    print(f\"{len(result.inserted_ids)} documents inserted.\")\n",
    "\n",
    "    # Move the JSON file to the new folder\n",
    "    old_file = file_path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    new_file = os.path.join(new_folder, f'moved_on_{now}_{file_name}')\n",
    "    shutil.move(old_file, new_file)\n",
    "    print(f\"{old_file} moved to {new_file}\")\n",
    "    \n",
    "    # Print the path to the new file\n",
    "    print(f\"JSON file moved to {new_file}\")\n",
    "else:\n",
    "    print(\"The collection is not empty.\")\n",
    "    # Read the data from a JSON file into a pandas DataFrame\n",
    "    df = pd.read_json(file_path)\n",
    "    df_new= df[['complaint_id']]\n",
    "    # print(df_new.columns)\n",
    "\n",
    "    projection = {'complaint_id': 1, '_id': 0}\n",
    "\n",
    "    # query the collection and retrieve only the complaint_id field\n",
    "    result = collection.find({}, projection)\n",
    "\n",
    "    # convert the result to a pandas DataFrame\n",
    "    df_old = pd.DataFrame(list(result))\n",
    "    df_old = df_old.rename(columns={'complaint_id':'old_complaint_id'})\n",
    "    # df_old['old_complaint_id'].nunique()\n",
    "\n",
    "    merged_df = pd.merge(df_new, df_old, left_on='complaint_id', right_on='old_complaint_id',how='left')\n",
    "    # merged_df.columns\n",
    "\n",
    "    new_records=merged_df[merged_df['complaint_id'].notna() & merged_df['old_complaint_id'].isna()]\n",
    "    \n",
    "    #new_records\n",
    "    all_records=df[df['complaint_id'].isin(new_records['complaint_id'])]\n",
    "\n",
    "    # insert the new records into the collection\n",
    "    records = all_records.to_dict('records')\n",
    "    result=collection.insert_many(records)\n",
    "    # Print the number of documents inserted\n",
    "    print(f\"{len(result.inserted_ids)} documents inserted.\")\n",
    "    print(\"New records inserted successfully to MongoDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection = client[DATABASE_NAME][COLLECTION_NAME]\n",
    "# count = collection.count_documents({})\n",
    "\n",
    "# # Check if the collection is empty or not\n",
    "# if count == 0:\n",
    "#     print(\"Collection is empty\")\n",
    "#     df = pd.read_json(file_path)\n",
    "#     # Convert the DataFrame to a list of dictionaries\n",
    "#     documents = df.to_dict(orient='records')\n",
    "#     # batch_size = 16000\n",
    "\n",
    "#     # Insert the documents in batches using insert_many()\n",
    "#     # for i in range(0, len(documents), batch_size):\n",
    "#     #     result = collection.insert_many(documents[i:i+batch_size])\n",
    "#     #     print(f\"{len(result.inserted_ids)} documents inserted in batch {i//batch_size + 1}.\")\n",
    "#     # Insert the data into the collection using insert_many()\n",
    "#     result = collection.insert_many(documents)\n",
    "#     print(f'Succesfully dumped records to Mongodb Collection={COLLECTION_NAME}')\n",
    "    \n",
    "# else:\n",
    "#     print(\"Collection is not empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from census.entity.config_entity import *\n",
    "from census.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_ingestion_dir': 'artifacts\\\\04_28_2023_16_41_45\\\\DataIngestion',\n",
       " 'data_feauture_store': 'artifacts\\\\04_28_2023_16_41_45\\\\DataIngestion\\\\DataFeatureStore',\n",
       " 'data_parquet_dir': 'artifacts\\\\04_28_2023_16_41_45\\\\DataIngestion\\\\DataParquetStore'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_i_config = DataIngestionConfig()\n",
    "d_i_config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts\\\\04_28_2023_16_41_45\\\\DataIngestion\\\\DataParquetStore\\\\DataIngested.parquet'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(d_i_config.data_parquet_dir,DATA_INGESTION_PARQUET_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from census.config.spark_manager import spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts\\\\04_28_2023_16_37_20\\\\DataIngestion\\\\DataFeatureStore\\\\DataIngested.json'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file_name in os.listdir(r'artifacts\\04_28_2023_16_37_20\\DataIngestion\\DataFeatureStore'):\n",
    "    json_file_path = os.path.join(r'artifacts\\04_28_2023_16_37_20\\DataIngestion\\DataFeatureStore', file_name)\n",
    "json_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark_session.read.json('dataingestion.json')\n",
    "print(df.count())\n",
    "len(df.columns)\n",
    "# if df.count() > 0:\n",
    "#     df.write.mode('overwrite').parquet(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
